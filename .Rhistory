require(rstan)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
require(rstan)
install.packages("tranlateR")
install.packages("RSelenium")
install.packages("rvest")
install.packages("tidyverse")
install.packages("RSelenium")
install.packages("rvest")
require(RSelenium)
require(rvest)
require(tidyverse)
rD <- rsDriver(browser="firefox", port=4545L, verbose=F)
remDr <- rD[["client"]]
remDr$navigate("https://www.fcc.gov/media/engineering/dtvmaps")
zip <- "30308"
remDr$findElement(using = "id", value = "startpoint")$sendKeysToElement(list(zip))
remDr$findElements("id", "btnSub")[[1]]$clickElement()
remDr$findElements("id", "btnSub")[[1]]$clickElement()
remDr$findElements("id", "btnSub")[[1]]$clickElement()
exp(-10)
exp(5)
exp(1)
exp(0.5)
exp(0)
exp(0.0001)
exp(-1)
exp(-10)
exp(-10+1)
exp(-10-1)
log(0.000123)
log(0.1)
log(0.01)
log(0.001)
log(0.00001)
setwd("~/Documents/GitHub/Media_volatility")
rm(list=ls())
require(plm)
require(stringr)
require(stargazer)
require(ggplot2)
require(reshape2)
require(urca)
require(lfe)
require(fixest)
require(lubridate)
require(DoubleML)
library(mediation)
library(DescTools)
library(tidyverse)
felm_DK_se <- function(reg_formula, df_panel){
# Estimate regressions with feols and felm
model <- feols(reg_formula, data = df_panel)
model_felm <- felm(reg_formula, data = df_panel)
stopifnot(length(model_felm$se) ==
length(summary(model, vcov = DK ~ period)$coeftable[,"Std. Error"]))
model_felm$se <- summary(model, vcov = DK ~ period)$coeftable[,"Std. Error"]
model_felm$tval <- summary(model, vcov = DK ~ period)$coeftable[,"t value"]
model_felm$pval <- summary(model, vcov = DK ~ period)$coeftable[,"Pr(>|t|)"]
return(model_felm)
}
get_quantile <- function(x, qnt, as_numeric = TRUE){
x_qnts <- cut(x, breaks = Quantile(x, probs = seq(0,1,1/qnt), na.rm = T),
labels = 1:qnt, include.lowest = TRUE)
if (as_numeric){
x_qnts <- as.numeric(x_qnts)
}
return(x_qnts)
}
# Import the panel data
clean_dir <- "~/Documents/DPhil/Clean_Data"
import_filename = paste(clean_dir, "FT/matched/BTR_FT_data.csv", sep = "/")
total_data <- read.csv(import_filename, stringsAsFactors = FALSE)
library(topicmodels)
library(tm)
text_data <- total_data %>%
filter(text_clean != "") %>%
select(Code, Date, intra_day, text_clean)
total_corpus <- Corpus(VectorSource(unlist(text_data[, "text_clean"])))
total_dtm <- DocumentTermMatrix(total_corpus, control = list(minsWordLength = 3))
print(paste("Dimensions of total_dtm are", dim(total_dtm)[1], "documents and",
dim(total_dtm)[2], "words in vocab"))
x<-col_sums(total_dtm)
x<-colSums(total_dtm)
total_dtm
require(slam)
x<-col_sums(total_dtm)
total_dtm <- total_dtm[,col_sums(total_dtm) > 10]
print(paste("Dimensions of total_dtm are", dim(total_dtm)[1], "documents and",
dim(total_dtm)[2], "words in vocab"))
vocab<-total_dtm$dimnames$Terms
set.seed(1234)
lda_gibbs <- LDA(total_dtm, k = 20, method = "Gibbs",
control = list(verbose = 1000, burnin = 2000, thin = 10, iter = 10000))
